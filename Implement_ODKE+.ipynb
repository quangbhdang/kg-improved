{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TtgTvE754HY4"
   },
   "source": [
    "# Knowledge Graph Pipeline: Proof-of-Concept (ODKE+)\n",
    "\n",
    "This notebook implements a production-grade, end-to-end pipeline for knowledge extraction, inspired by the ODKE+ paper: https://arxiv.org/pdf/2509.04696\n",
    "\n",
    "It performs the following steps:\n",
    "1.  **Crawl** target websites for unstructured text.\n",
    "2.  **Extract** structured data using an LLM (Gemini) guided by a Pydantic ontology.\n",
    "3.  **Ground** the extracted facts using a second, lightweight LLM to verify them against the source text.\n",
    "4.  **Corroborate** the facts by checking for staleness (deactivating old data) and resolving conflicts with existing data.\n",
    "5.  **Ingest** the \"winning\" facts into a Neo4j graph, updating the central node properties.\n",
    "6.  **Infer** new relationships based on the *active* state of the graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T06:48:19.576804Z",
     "iopub.status.busy": "2025-12-22T06:48:19.576621Z",
     "iopub.status.idle": "2025-12-22T06:48:20.192609Z",
     "shell.execute_reply": "2025-12-22T06:48:20.191458Z",
     "shell.execute_reply.started": "2025-12-22T06:48:19.576791Z"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "# Block 1: Setup\n",
    "# ==============================================================================\n",
    "!pip install -q neo4j beautifulsoup4 requests google-generativeai python-dotenv huggingface_hub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-12-22T06:49:18.591597Z",
     "iopub.status.busy": "2025-12-22T06:49:18.591422Z",
     "iopub.status.idle": "2025-12-22T06:49:19.087245Z",
     "shell.execute_reply": "2025-12-22T06:49:19.086304Z",
     "shell.execute_reply.started": "2025-12-22T06:49:18.591582Z"
    },
    "id": "nqoh8Ad4JTly",
    "outputId": "0aac40d1-2d22-42d0-ff16-4d4ac0ba4aee"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# from google.colab import userdata\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "from typing import Optional, List, Type, TypeVar, Generic\n",
    "import enum\n",
    "from datetime import datetime\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "# from google import genai\n",
    "import json\n",
    "from neo4j import GraphDatabase, Session, Transaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oz1Eut6u4jxx"
   },
   "source": [
    "## Configuration\n",
    "\n",
    "This block writes all static configuration to a `config.py` file. This separates our logic from our configuration, making the pipeline easier to manage.\n",
    "\n",
    "Get your API Key here: https://neo4j.com and https://aistudio.google.com\n",
    "\n",
    "It contains:\n",
    "* API keys (add them to Colab Secrets).\n",
    "* Target URLs for our crawler.\n",
    "* The Corroborator's \"Trust Score\" settings for different source domains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wN5mZBnXJAQP",
    "outputId": "4ea11c1f-816c-4800-de9a-98a1d012056d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing config.py\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Block 2: config.py\n",
    "# ==============================================================================\n",
    "%%writefile config.py\n",
    "import os\n",
    "from google.colab import userdata\n",
    "\n",
    "# --- API Keys ---\n",
    "NEO4J_URI = userdata.get('NEO4J_URI')\n",
    "NEO4J_USERNAME = userdata.get('NEO4J_USERNAME')\n",
    "NEO4J_PASSWORD = userdata.get('NEO4J_PASSWORD')\n",
    "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY')\n",
    "\n",
    "# --- Target URLs for webscraping ---\n",
    "TARGET_URLS = [\n",
    "    \"https://www.vblh.de/privatkunden/geldanlage/sparbrief.html\",\n",
    "    \"https://www.vblh.de/privatkunden/geldanlage/tagesgeld.html\"\n",
    "]\n",
    "\n",
    "FILIAL_URLS = [\n",
    "    \"https://www.vblh.de/ueber-uns/filialen/bispingen.html\",\n",
    "    \"https://www.vblh.de/ueber-uns/filialen/soltau.html\"\n",
    "]\n",
    "\n",
    "# --- Corroborator Configuration ---\n",
    "SOURCE_TRUST_SCORES = {\n",
    "    \"https://www.vblh.de/\": 0.9,          # Trust scores for different types of sources\n",
    "    \"https://intern.vblh.de/\": 0.95\n",
    "}\n",
    "\n",
    "def get_trust_score(url: str) -> float:\n",
    "    \"\"\"Findet den passenden Trust Score fÃ¼r eine gegebene URL.\"\"\"\n",
    "    for domain, score in SOURCE_TRUST_SCORES.items():\n",
    "        if url.startswith(domain):\n",
    "            return score\n",
    "    return 0.5 # some standard-Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GWJfZ6625LDg"
   },
   "source": [
    "## The Data Ontology\n",
    "\n",
    "This block defines our \"Ontology\"â€”the strict Pydantic schemas that guide the LLM extraction.\n",
    "\n",
    "* `ProvableFact`: The core atomic unit. It forces the LLM to return both a `value` and the `evidence` snippet that proves it.\n",
    "* `ProvenanceModel`: The metadata for each fact, including its source URL and trust score.\n",
    "* `ExtractionPackage`: A generic container that bundles the `data` (our models) with its `metadata`.\n",
    "* `KnowledgeGraphData` / `BranchData`: The top-level schemas the LLM must populate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nV60jLa-JbZ4",
    "outputId": "b7ffb8b0-e5c2-4002-d72e-25dbbd72af2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ontology.py\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Block 3: ontology.py\n",
    "# ==============================================================================\n",
    "%%writefile ontology.py\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, List, TypeVar, Generic\n",
    "import enum\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Enums ---\n",
    "class ProductTypeEnum(str, enum.Enum):\n",
    "    \"\"\"Defines the allowed product types.\"\"\"\n",
    "    INTEREST_PRODUCT = \"InterestProduct\"\n",
    "    CHECKING_ACCOUNT = \"CheckingAccount\"\n",
    "    SECURITY = \"Security\"\n",
    "\n",
    "class RiskClassStrEnum(str, enum.Enum):\n",
    "    \"\"\"Defines the risk classes as string enums.\"\"\"\n",
    "    ONE = \"1\"\n",
    "    TWO = \"2\"\n",
    "    THREE = \"3\"\n",
    "    FOUR = \"4\"\n",
    "    FIVE = \"5\"\n",
    "\n",
    "class RoleTypeEnum(str, enum.Enum):\n",
    "    \"\"\"Defines the allowed role types for employees.\"\"\"\n",
    "    ADVISOR = \"Advisor\"\n",
    "    SERVICE = \"Service\"\n",
    "\n",
    "# --- Atomic Fact Model ---\n",
    "class ProvableFact(BaseModel):\n",
    "    \"\"\"\n",
    "    A single, provable fact, consisting of the extracted value\n",
    "    and the exact text snippet (evidence) that supports it.\n",
    "    \"\"\"\n",
    "    value: str = Field(..., description=\"The extracted fact, e.g., 'Max Musterman' or 'Branch Buchholz'.\")\n",
    "    evidence: str = Field(..., description=\"The exact text snippet from the source that proves this fact.\")\n",
    "\n",
    "# --- Metadata Models ---\n",
    "class ProvenanceModel(BaseModel):\n",
    "    \"\"\"\n",
    "    Describes the origin (provenance) and timestamp (versioning)\n",
    "    of a single extraction.\n",
    "    \"\"\"\n",
    "    url: str\n",
    "    retrieved_at: datetime = Field(default_factory=datetime.now)\n",
    "    trust_score: float\n",
    "\n",
    "T = TypeVar('T', bound=BaseModel)\n",
    "class ExtractionPackage(BaseModel, Generic[T]):\n",
    "    \"\"\"\n",
    "    A generic container that bundles the extracted payload (e.g., BranchData\n",
    "    or KnowledgeGraphData) with its provenance metadata.\n",
    "    This is the object passed to the ingestor.\n",
    "    \"\"\"\n",
    "    metadata: ProvenanceModel\n",
    "    data: T\n",
    "\n",
    "class GrounderResponse(BaseModel):\n",
    "    \"\"\"The schema for the Grounder's simple boolean response.\"\"\"\n",
    "    is_grounded: bool\n",
    "\n",
    "# --- Data Models (Ontology) ---\n",
    "class EmployeeModel(BaseModel):\n",
    "    \"\"\"Describes a single employee.\"\"\"\n",
    "    name: ProvableFact\n",
    "    email: Optional[ProvableFact] = None\n",
    "    phone: Optional[ProvableFact] = None\n",
    "    role_type: RoleTypeEnum = Field(..., description=\"Classify the employee's role as 'Advisor' or 'Service'.\")\n",
    "\n",
    "class BranchModel(BaseModel):\n",
    "    \"\"\"Describes a single bank branch.\"\"\"\n",
    "    name: ProvableFact\n",
    "    address: Optional[ProvableFact] = None\n",
    "    employees: List[EmployeeModel] = []\n",
    "\n",
    "class BranchData(BaseModel):\n",
    "    \"\"\"The top-level schema for extracting branch information.\"\"\"\n",
    "    branch: BranchModel\n",
    "\n",
    "class ConditionModel(BaseModel):\n",
    "    \"\"\"Describes a single financial condition.\"\"\"\n",
    "    type: Optional[ProvableFact] = None\n",
    "    min_amount: Optional[int] = None\n",
    "    max_amount: Optional[int] = None\n",
    "    term_years: Optional[int] = None\n",
    "    interest_rate: Optional[ProvableFact] = None\n",
    "\n",
    "class FAQModel(BaseModel):\n",
    "    \"\"\"Describes a single Question-Answer pair.\"\"\"\n",
    "    question: ProvableFact\n",
    "    answer: ProvableFact\n",
    "\n",
    "class ProductModel(BaseModel):\n",
    "    \"\"\"Describes the core product.\"\"\"\n",
    "    name: ProvableFact\n",
    "    description: Optional[ProvableFact] = None\n",
    "\n",
    "class ProductTypeModel(BaseModel):\n",
    "    \"\"\"Describes the classified type of the product.\"\"\"\n",
    "    name: ProductTypeEnum\n",
    "\n",
    "class RiskClassModel(BaseModel):\n",
    "    \"\"\"Describes the estimated risk class of the product.\"\"\"\n",
    "    risk_class: RiskClassStrEnum = Field(..., description=\"Estimate the product risk and select the appropriate class from '1' to '5'.\")\n",
    "\n",
    "    @property\n",
    "    def class_as_integer(self) -> int:\n",
    "        return int(self.risk_class.value)\n",
    "\n",
    "class KnowledgeGraphData(BaseModel):\n",
    "    \"\"\"The top-level schema for extracting financial product information.\"\"\"\n",
    "    product: ProductModel\n",
    "    product_type: ProductTypeModel\n",
    "    risk_class: RiskClassModel\n",
    "    conditions: Optional[List[ConditionModel]] = None\n",
    "    faqs: Optional[List[FAQModel]] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "883a0799",
    "outputId": "ac87d040-f1b9-427e-9a60-1b03ae44e9ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- JSON Schema for KnowledgeGraphData ---\n",
      "{\n",
      "  \"$defs\": {\n",
      "    \"ConditionModel\": {\n",
      "      \"description\": \"Describes a single financial condition.\",\n",
      "      \"properties\": {\n",
      "        \"type\": {\n",
      "          \"anyOf\": [\n",
      "            {\n",
      "              \"$ref\": \"#/$defs/ProvableFact\"\n",
      "            },\n",
      "            {\n",
      "              \"type\": \"null\"\n",
      "            }\n",
      "          ],\n",
      "          \"default\": null\n",
      "        },\n",
      "        \"min_amount\": {\n",
      "          \"anyOf\": [\n",
      "            {\n",
      "              \"type\": \"integer\"\n",
      "            },\n",
      "            {\n",
      "              \"type\": \"null\"\n",
      "            }\n",
      "          ],\n",
      "          \"default\": null,\n",
      "          \"title\": \"Min Amount\"\n",
      "        },\n",
      "        \"max_amount\": {\n",
      "          \"anyOf\": [\n",
      "            {\n",
      "              \"type\": \"integer\"\n",
      "            },\n",
      "            {\n",
      "              \"type\": \"null\"\n",
      "            }\n",
      "          ],\n",
      "          \"default\": null,\n",
      "          \"title\": \"Max Amount\"\n",
      "        },\n",
      "        \"term_years\": {\n",
      "          \"anyOf\": [\n",
      "            {\n",
      "              \"type\": \"integer\"\n",
      "            },\n",
      "            {\n",
      "              \"type\": \"null\"\n",
      "            }\n",
      "          ],\n",
      "          \"default\": null,\n",
      "          \"title\": \"Term Years\"\n",
      "        },\n",
      "        \"interest_rate\": {\n",
      "          \"anyOf\": [\n",
      "            {\n",
      "              \"$ref\": \"#/$defs/ProvableFact\"\n",
      "            },\n",
      "            {\n",
      "              \"type\": \"null\"\n",
      "            }\n",
      "          ],\n",
      "          \"default\": null\n",
      "        }\n",
      "      },\n",
      "      \"title\": \"ConditionModel\",\n",
      "      \"type\": \"object\"\n",
      "    },\n",
      "    \"FAQModel\": {\n",
      "      \"description\": \"Describes a single Question-Answer pair.\",\n",
      "      \"properties\": {\n",
      "        \"question\": {\n",
      "          \"$ref\": \"#/$defs/ProvableFact\"\n",
      "        },\n",
      "        \"answer\": {\n",
      "          \"$ref\": \"#/$defs/ProvableFact\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"question\",\n",
      "        \"answer\"\n",
      "      ],\n",
      "      \"title\": \"FAQModel\",\n",
      "      \"type\": \"object\"\n",
      "    },\n",
      "    \"ProductModel\": {\n",
      "      \"description\": \"Describes the core product.\",\n",
      "      \"properties\": {\n",
      "        \"name\": {\n",
      "          \"$ref\": \"#/$defs/ProvableFact\"\n",
      "        },\n",
      "        \"description\": {\n",
      "          \"anyOf\": [\n",
      "            {\n",
      "              \"$ref\": \"#/$defs/ProvableFact\"\n",
      "            },\n",
      "            {\n",
      "              \"type\": \"null\"\n",
      "            }\n",
      "          ],\n",
      "          \"default\": null\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"name\"\n",
      "      ],\n",
      "      \"title\": \"ProductModel\",\n",
      "      \"type\": \"object\"\n",
      "    },\n",
      "    \"ProductTypeEnum\": {\n",
      "      \"description\": \"Defines the allowed product types.\",\n",
      "      \"enum\": [\n",
      "        \"InterestProduct\",\n",
      "        \"CheckingAccount\",\n",
      "        \"Security\"\n",
      "      ],\n",
      "      \"title\": \"ProductTypeEnum\",\n",
      "      \"type\": \"string\"\n",
      "    },\n",
      "    \"ProductTypeModel\": {\n",
      "      \"description\": \"Describes the classified type of the product.\",\n",
      "      \"properties\": {\n",
      "        \"name\": {\n",
      "          \"$ref\": \"#/$defs/ProductTypeEnum\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"name\"\n",
      "      ],\n",
      "      \"title\": \"ProductTypeModel\",\n",
      "      \"type\": \"object\"\n",
      "    },\n",
      "    \"ProvableFact\": {\n",
      "      \"description\": \"A single, provable fact, consisting of the extracted value\\nand the exact text snippet (evidence) that supports it.\",\n",
      "      \"properties\": {\n",
      "        \"value\": {\n",
      "          \"description\": \"The extracted fact, e.g., 'Max Musterman' or 'Branch Buchholz'.\",\n",
      "          \"title\": \"Value\",\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"evidence\": {\n",
      "          \"description\": \"The exact text snippet from the source that proves this fact.\",\n",
      "          \"title\": \"Evidence\",\n",
      "          \"type\": \"string\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"value\",\n",
      "        \"evidence\"\n",
      "      ],\n",
      "      \"title\": \"ProvableFact\",\n",
      "      \"type\": \"object\"\n",
      "    },\n",
      "    \"RiskClassModel\": {\n",
      "      \"description\": \"Describes the estimated risk class of the product.\",\n",
      "      \"properties\": {\n",
      "        \"risk_class\": {\n",
      "          \"$ref\": \"#/$defs/RiskClassStrEnum\",\n",
      "          \"description\": \"Estimate the product risk and select the appropriate class from '1' to '5'.\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"risk_class\"\n",
      "      ],\n",
      "      \"title\": \"RiskClassModel\",\n",
      "      \"type\": \"object\"\n",
      "    },\n",
      "    \"RiskClassStrEnum\": {\n",
      "      \"description\": \"Defines the risk classes as string enums.\",\n",
      "      \"enum\": [\n",
      "        \"1\",\n",
      "        \"2\",\n",
      "        \"3\",\n",
      "        \"4\",\n",
      "        \"5\"\n",
      "      ],\n",
      "      \"title\": \"RiskClassStrEnum\",\n",
      "      \"type\": \"string\"\n",
      "    }\n",
      "  },\n",
      "  \"description\": \"The top-level schema for extracting financial product information.\",\n",
      "  \"properties\": {\n",
      "    \"product\": {\n",
      "      \"$ref\": \"#/$defs/ProductModel\"\n",
      "    },\n",
      "    \"product_type\": {\n",
      "      \"$ref\": \"#/$defs/ProductTypeModel\"\n",
      "    },\n",
      "    \"risk_class\": {\n",
      "      \"$ref\": \"#/$defs/RiskClassModel\"\n",
      "    },\n",
      "    \"conditions\": {\n",
      "      \"anyOf\": [\n",
      "        {\n",
      "          \"items\": {\n",
      "            \"$ref\": \"#/$defs/ConditionModel\"\n",
      "          },\n",
      "          \"type\": \"array\"\n",
      "        },\n",
      "        {\n",
      "          \"type\": \"null\"\n",
      "        }\n",
      "      ],\n",
      "      \"default\": null,\n",
      "      \"title\": \"Conditions\"\n",
      "    },\n",
      "    \"faqs\": {\n",
      "      \"anyOf\": [\n",
      "        {\n",
      "          \"items\": {\n",
      "            \"$ref\": \"#/$defs/FAQModel\"\n",
      "          },\n",
      "          \"type\": \"array\"\n",
      "        },\n",
      "        {\n",
      "          \"type\": \"null\"\n",
      "        }\n",
      "      ],\n",
      "      \"default\": null,\n",
      "      \"title\": \"Faqs\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"product\",\n",
      "    \"product_type\",\n",
      "    \"risk_class\"\n",
      "  ],\n",
      "  \"title\": \"KnowledgeGraphData\",\n",
      "  \"type\": \"object\"\n",
      "}\n",
      "\n",
      "--- JSON Schema for BranchData ---\n",
      "{\n",
      "  \"$defs\": {\n",
      "    \"BranchModel\": {\n",
      "      \"description\": \"Describes a single bank branch.\",\n",
      "      \"properties\": {\n",
      "        \"name\": {\n",
      "          \"$ref\": \"#/$defs/ProvableFact\"\n",
      "        },\n",
      "        \"address\": {\n",
      "          \"anyOf\": [\n",
      "            {\n",
      "              \"$ref\": \"#/$defs/ProvableFact\"\n",
      "            },\n",
      "            {\n",
      "              \"type\": \"null\"\n",
      "            }\n",
      "          ],\n",
      "          \"default\": null\n",
      "        },\n",
      "        \"employees\": {\n",
      "          \"default\": [],\n",
      "          \"items\": {\n",
      "            \"$ref\": \"#/$defs/EmployeeModel\"\n",
      "          },\n",
      "          \"title\": \"Employees\",\n",
      "          \"type\": \"array\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"name\"\n",
      "      ],\n",
      "      \"title\": \"BranchModel\",\n",
      "      \"type\": \"object\"\n",
      "    },\n",
      "    \"EmployeeModel\": {\n",
      "      \"description\": \"Describes a single employee.\",\n",
      "      \"properties\": {\n",
      "        \"name\": {\n",
      "          \"$ref\": \"#/$defs/ProvableFact\"\n",
      "        },\n",
      "        \"email\": {\n",
      "          \"anyOf\": [\n",
      "            {\n",
      "              \"$ref\": \"#/$defs/ProvableFact\"\n",
      "            },\n",
      "            {\n",
      "              \"type\": \"null\"\n",
      "            }\n",
      "          ],\n",
      "          \"default\": null\n",
      "        },\n",
      "        \"phone\": {\n",
      "          \"anyOf\": [\n",
      "            {\n",
      "              \"$ref\": \"#/$defs/ProvableFact\"\n",
      "            },\n",
      "            {\n",
      "              \"type\": \"null\"\n",
      "            }\n",
      "          ],\n",
      "          \"default\": null\n",
      "        },\n",
      "        \"role_type\": {\n",
      "          \"$ref\": \"#/$defs/RoleTypeEnum\",\n",
      "          \"description\": \"Classify the employee's role as 'Advisor' or 'Service'.\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"name\",\n",
      "        \"role_type\"\n",
      "      ],\n",
      "      \"title\": \"EmployeeModel\",\n",
      "      \"type\": \"object\"\n",
      "    },\n",
      "    \"ProvableFact\": {\n",
      "      \"description\": \"A single, provable fact, consisting of the extracted value\\nand the exact text snippet (evidence) that supports it.\",\n",
      "      \"properties\": {\n",
      "        \"value\": {\n",
      "          \"description\": \"The extracted fact, e.g., 'Max Musterman' or 'Branch Buchholz'.\",\n",
      "          \"title\": \"Value\",\n",
      "          \"type\": \"string\"\n",
      "        },\n",
      "        \"evidence\": {\n",
      "          \"description\": \"The exact text snippet from the source that proves this fact.\",\n",
      "          \"title\": \"Evidence\",\n",
      "          \"type\": \"string\"\n",
      "        }\n",
      "      },\n",
      "      \"required\": [\n",
      "        \"value\",\n",
      "        \"evidence\"\n",
      "      ],\n",
      "      \"title\": \"ProvableFact\",\n",
      "      \"type\": \"object\"\n",
      "    },\n",
      "    \"RoleTypeEnum\": {\n",
      "      \"description\": \"Defines the allowed role types for employees.\",\n",
      "      \"enum\": [\n",
      "        \"Advisor\",\n",
      "        \"Service\"\n",
      "      ],\n",
      "      \"title\": \"RoleTypeEnum\",\n",
      "      \"type\": \"string\"\n",
      "    }\n",
      "  },\n",
      "  \"description\": \"The top-level schema for extracting branch information.\",\n",
      "  \"properties\": {\n",
      "    \"branch\": {\n",
      "      \"$ref\": \"#/$defs/BranchModel\"\n",
      "    }\n",
      "  },\n",
      "  \"required\": [\n",
      "    \"branch\"\n",
      "  ],\n",
      "  \"title\": \"BranchData\",\n",
      "  \"type\": \"object\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from ontology import KnowledgeGraphData, BranchData\n",
    "import json\n",
    "\n",
    "print(\"--- JSON Schema for KnowledgeGraphData ---\")\n",
    "kg_schema = KnowledgeGraphData.model_json_schema()\n",
    "print(json.dumps(kg_schema, indent=2))\n",
    "\n",
    "print(\"\\n--- JSON Schema for BranchData ---\")\n",
    "branch_schema = BranchData.model_json_schema()\n",
    "print(json.dumps(branch_schema, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRaQ758o5WSi"
   },
   "source": [
    "## The ETL Logic\n",
    "\n",
    "This is the core of the application. It contains all the functions that perform the Extract, Transform, and Load (ETL) process, following the ODKE+ architecture.\n",
    "\n",
    "1.  **Crawler (`get_webpage_content`):** Fetches and cleans text from a URL.\n",
    "2.  **Extractor (`extract_structured_data`):** Uses Gemini Pro (LLM 1) to convert text into a structured Pydantic object based on our `ontology.py`.\n",
    "3.  **Grounder (`is_fact_grounded`, `ground_package`):** Uses Gemini Flash (LLM 2) to verify that every single fact (`ProvableFact`) is supported by its evidence. Facts that fail are \"nulled\" (removed).\n",
    "4.  **Ingestor & Corroborator (`_tx_...` functions):** A series of robust Neo4j transactions that:\n",
    "\n",
    "    a.  **Check for Staleness:** Deactivates all old facts from the source URL (`is_active = false`).\n",
    "\n",
    "    b.  **Corroborate Conflicts:** Checks for active facts from *other* sources.\n",
    "\n",
    "    c.  **Score & Ingest:** Applies the \"Freshness > Trust\" algorithm to determine a \"winner\".\n",
    "\n",
    "    d.  **Activate:** Writes the \"winner's\" data to the main node (e.g., `Product.interest_rate`) and sets its `FROM_SOURCE` relationship to `is_active = true`.\n",
    "    \n",
    "5.  **Inference (`create_inferred_relationships`):** Cleans up old inferred relationships and creates new ones *only* between currently active nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5_MiWnWCJuNk",
    "outputId": "bd26700d-af6b-4d89-806d-9b2b197f0296"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing pipeline.py\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Block 4: pipeline.py\n",
    "# ==============================================================================\n",
    "%%writefile pipeline.py\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from google import genai\n",
    "import json\n",
    "from neo4j import GraphDatabase, Session, Transaction\n",
    "from typing import Optional, List, Type\n",
    "import enum\n",
    "from datetime import datetime\n",
    "\n",
    "# Import our custom modules\n",
    "import config\n",
    "from ontology import *\n",
    "\n",
    "# --- Client Initialization ---\n",
    "client = genai.Client(api_key=config.GOOGLE_API_KEY)\n",
    "\n",
    "# ==============================================================================\n",
    "# 4.1 CRAWLER\n",
    "# ==============================================================================\n",
    "def get_webpage_content(url: str) -> Optional[str]:\n",
    "    \"\"\"Fetches the visible text from a webpage.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        for script in soup([\"script\", \"style\"]): script.extract()\n",
    "        text = soup.get_text(separator=\" \")\n",
    "        lines = (line.strip() for line in text.splitlines())\n",
    "        chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "        text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "        return text\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching webpage {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Rewrite the crawler to use the NASDAS 100 sample data instead\n",
    "\n",
    "\n",
    "\n",
    "# ==============================================================================\n",
    "# 4.2 EXTRACTOR\n",
    "# ==============================================================================\n",
    "def extract_structured_data(text: str, schema_class: Type[BaseModel]) -> Optional[BaseModel]:\n",
    "    \"\"\"Extracts knowledge from text using the Gemini API.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Extract all relevant information from the following text and populate the provided data schema.\n",
    "    IMPORTANT: The schema requires a `ProvableFact` object for many facts.\n",
    "    You must fill the `value` field (the fact) AND the `evidence` field (the text snippet from the source text\n",
    "    that proves the fact).\n",
    "\n",
    "    **Text to Analyze:**\n",
    "    ---\n",
    "    {text}\n",
    "    ---\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Gemini 2.5 flash\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.5-pro\",\n",
    "            contents=prompt,\n",
    "            config={\n",
    "                \"response_mime_type\": \"application/json\",\n",
    "                \"response_schema\": schema_class,\n",
    "            }\n",
    "        )\n",
    "        if response.parsed is None:\n",
    "            print(\"ERROR: The SDK could not parse the response into the Pydantic schema.\")\n",
    "            return None\n",
    "        print(f\"Model response for schema '{schema_class.__name__}' parsed successfully.\")\n",
    "        return response.parsed\n",
    "    except Exception as e:\n",
    "        print(f\"An unexpected ERROR occurred during extraction: {e}\")\n",
    "        return None\n",
    "\n",
    "# ==============================================================================\n",
    "# 4.3 GROUNDER\n",
    "# ==============================================================================\n",
    "def is_fact_grounded(fact: str, evidence: str) -> bool:\n",
    "    \"\"\"Checks with a 'lightweight' LLM if a fact is supported by an evidence snippet.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    Verify if the following fact can be inferred from the provided text snippet.\n",
    "    The fact must be explicitly mentioned or directly logically derivable.\n",
    "\n",
    "    Fact to verify:\n",
    "    \"{fact}\"\n",
    "\n",
    "    Can this fact be derived from the following snippet?:\n",
    "    \"{evidence}\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash-lite\",\n",
    "            contents=prompt,\n",
    "            config={\n",
    "                \"response_mime_type\": \"application/json\",\n",
    "                \"response_schema\": GrounderResponse,\n",
    "            }\n",
    "        )\n",
    "        if response.parsed:\n",
    "            return response.parsed.is_grounded\n",
    "        else:\n",
    "            print(f\"GROUNDER WARNING: Could not parse response. Defaulting to 'False'.\")\n",
    "            return False\n",
    "    except Exception as e:\n",
    "        print(f\"GROUNDER ERROR: {e}. Defaulting to 'False'.\")\n",
    "        return False\n",
    "\n",
    "def _ground_model_recursive(model_instance: BaseModel):\n",
    "    \"\"\"Recursively iterates through a Pydantic model and nullifies any ungrounded facts.\"\"\"\n",
    "    if model_instance is None: return\n",
    "\n",
    "    # Use .model_fields for Pydantic v2+\n",
    "    for field_name, field_obj in model_instance.model_fields.items():\n",
    "        field_value = getattr(model_instance, field_name)\n",
    "        if field_value is None: continue\n",
    "\n",
    "        if isinstance(field_value, ProvableFact):\n",
    "            if not field_value.value or not field_value.evidence:\n",
    "                print(f\"--- âš ï¸ GROUNDING SKIPPED: Empty value/evidence for {field_name}. Removing.\")\n",
    "                setattr(model_instance, field_name, None)\n",
    "                continue\n",
    "\n",
    "            is_grounded = is_fact_grounded(field_value.value, field_value.evidence)\n",
    "            if not is_grounded:\n",
    "                print(f\"--- âŒ GROUNDING FAILED: Fact '{field_value.value}' (for field '{field_name}') will be removed.\")\n",
    "                setattr(model_instance, field_name, None)\n",
    "            else:\n",
    "                print(f\"--- âœ… GROUNDING PASSED: Fact '{field_value.value}' (for field '{field_name}')\")\n",
    "\n",
    "        elif isinstance(field_value, BaseModel):\n",
    "            _ground_model_recursive(field_value)\n",
    "        elif isinstance(field_value, list):\n",
    "            for item in field_value:\n",
    "                if isinstance(item, BaseModel):\n",
    "                    _ground_model_recursive(item)\n",
    "\n",
    "def ground_package(package: ExtractionPackage) -> ExtractionPackage:\n",
    "    \"\"\"Takes an ExtractionPackage and validates all ProvableFact instances within it.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*30 + f\"\\nðŸ”¬ STARTING GROUNDING PROCESS for {package.metadata.url}\\n\" + \"=\"*30)\n",
    "    _ground_model_recursive(package.data)\n",
    "    print(f\"ðŸ”¬ GROUNDING PROCESS for {package.metadata.url} COMPLETED.\")\n",
    "    return package\n",
    "\n",
    "# ==============================================================================\n",
    "# 4.4 INGESTOR & CORROBORATOR\n",
    "# ==============================================================================\n",
    "def get_node_props(model: BaseModel) -> dict:\n",
    "    \"\"\"Converts a Pydantic model into a flat dictionary of VALUES for Neo4j node properties.\"\"\"\n",
    "    props = {}\n",
    "    if model is None: return props\n",
    "    # Use .model_fields.items() for Pydantic v2+\n",
    "    for field_name, field_info in model.model_fields.items():\n",
    "        field_value = getattr(model, field_name)\n",
    "        if isinstance(field_value, ProvableFact):\n",
    "            if field_value.value is not None: props[field_name] = field_value.value\n",
    "        elif isinstance(field_value, enum.Enum):\n",
    "             props[field_name] = field_value.value\n",
    "        elif isinstance(field_value, (str, int, float, bool)) or field_value is None:\n",
    "            props[field_name] = field_value\n",
    "    return props\n",
    "\n",
    "def get_rel_props(model: BaseModel) -> dict:\n",
    "    \"\"\"Converts a Pydantic model into a flat dictionary of EVIDENCE snippets for Neo4j relationship properties.\"\"\"\n",
    "    props = {}\n",
    "    if model is None: return props\n",
    "    for field_name, field_info in model.model_fields.items():\n",
    "        field_value = getattr(model, field_name)\n",
    "        if isinstance(field_value, ProvableFact):\n",
    "            if field_value.evidence is not None: props[f\"{field_name}_evidence\"] = field_value.evidence\n",
    "    return props\n",
    "\n",
    "def _tx_corroborate_and_ingest(\n",
    "    tx: Transaction,\n",
    "    node_label: str,\n",
    "    node_key: str,\n",
    "    node_key_value: str,\n",
    "    new_node_props: dict,\n",
    "    new_rel_props: dict,\n",
    "    meta: ProvenanceModel\n",
    "):\n",
    "    \"\"\"Executes the Corroborator logic (Model B) in a single transaction.\"\"\"\n",
    "\n",
    "    new_rel_props['retrieved_at'] = meta.retrieved_at\n",
    "    new_rel_props['trust_score'] = meta.trust_score\n",
    "\n",
    "    query_find_old = f\"\"\"\n",
    "    MATCH (n:{node_label} {{{node_key}: $key_value}})-[r_alt:FROM_SOURCE {{is_active: true}}]->(q_alt:Source)\n",
    "    WHERE q_alt.url <> $url\n",
    "    RETURN r_alt.retrieved_at AS old_ts, r_alt.trust_score AS old_trust\n",
    "    \"\"\"\n",
    "    result = tx.run(query_find_old, key_value=node_key_value, url=meta.url)\n",
    "    old_fact = result.single()\n",
    "\n",
    "    is_candidate_winner = False\n",
    "    if not old_fact:\n",
    "        is_candidate_winner = True\n",
    "    else:\n",
    "        if meta.retrieved_at > old_fact['old_ts']: is_candidate_winner = True\n",
    "        elif meta.retrieved_at == old_fact['old_ts']:\n",
    "            if meta.trust_score >= old_fact['old_trust']: is_candidate_winner = True\n",
    "            else: is_candidate_winner = False\n",
    "        else: is_candidate_winner = False\n",
    "\n",
    "    tx.run(f\"MERGE (q:Source {{url: $url}}) MERGE (n:{node_label} {{{node_key}: $key_value}})\",\n",
    "           url=meta.url, key_value=node_key_value)\n",
    "\n",
    "    if is_candidate_winner:\n",
    "        print(f\"--- ðŸ† CORROBORATOR: NEW wins for {node_key_value}\")\n",
    "        tx.run(f\"\"\"\n",
    "        MATCH (n:{node_label} {{{node_key}: $key_value}})\n",
    "        OPTIONAL MATCH (n)-[r_alt:FROM_SOURCE {{is_active: true}}]->()\n",
    "        SET n = $node_props, r_alt.is_active = false\n",
    "        \"\"\", key_value=node_key_value, node_props=new_node_props)\n",
    "\n",
    "        new_rel_props['is_active'] = True\n",
    "        tx.run(f\"\"\"\n",
    "        MATCH (n:{node_label} {{{node_key}: $key_value}}) MATCH (q:Source {{url: $url}})\n",
    "        MERGE (n)-[r_new:FROM_SOURCE]->(q) SET r_new = $rel_props\n",
    "        \"\"\", key_value=node_key_value, url=meta.url, rel_props=new_rel_props)\n",
    "    else:\n",
    "        print(f\"--- ðŸ›¡ï¸ CORROBORATOR: OLD wins for {node_key_value}\")\n",
    "        new_rel_props['is_active'] = False\n",
    "        tx.run(f\"\"\"\n",
    "        MATCH (n:{node_label} {{{node_key}: $key_value}}) MATCH (q:Source {{url: $url}})\n",
    "        MERGE (n)-[r_new:FROM_SOURCE]->(q) SET r_new = $rel_props\n",
    "        \"\"\", key_value=node_key_value, url=meta.url, rel_props=new_rel_props)\n",
    "\n",
    "def _tx_ingest_product_package(tx: Transaction, package: ExtractionPackage[KnowledgeGraphData]):\n",
    "    \"\"\"Executes the entire product ingestion in a single transaction.\"\"\"\n",
    "    data = package.data\n",
    "    meta = package.metadata\n",
    "\n",
    "    print(f\"--- â³ STALENESS-CHECK: Deactivating old Product-facts from {meta.url}...\")\n",
    "    tx.run(\"MATCH (n:Product|Condition|FAQ)-[r:FROM_SOURCE {is_active: true}]->(q:Source {url: $url}) SET r.is_active = false\", url=meta.url)\n",
    "\n",
    "    if not data.product or not data.product.name: return\n",
    "    product_name = data.product.name.value\n",
    "    print(f\"Processing Product: {product_name} from {meta.url}\")\n",
    "    product_node_props = get_node_props(data.product)\n",
    "    product_node_props['name'] = product_name\n",
    "    _tx_corroborate_and_ingest(tx, \"Product\", \"name\", product_name, product_node_props, get_rel_props(data.product), meta)\n",
    "\n",
    "    if data.product_type and data.product_type.name:\n",
    "        type_name = data.product_type.name.value\n",
    "        tx.run(\"MATCH (p:Product {name: $p_name}) MERGE (pt:ProductType {name: $t_name}) MERGE (p)-[:HAS_PRODUCT_TYPE]->(pt)\", p_name=product_name, t_name=type_name)\n",
    "\n",
    "    if data.risk_class and data.risk_class.risk_class:\n",
    "        class_value = data.risk_class.risk_class.value\n",
    "        tx.run(\"MATCH (p:Product {name: $p_name}) MERGE (s:RiskClass {risk_class: $c_value}) MERGE (p)-[:HAS_RISK_CLASS]->(s)\", p_name=product_name, c_value=class_value)\n",
    "\n",
    "    if data.conditions:\n",
    "        for condition in data.conditions:\n",
    "            if condition is None or condition.interest_rate is None: continue\n",
    "            key = f\"{product_name}_{condition.min_amount}_{condition.term_years}\"\n",
    "            condition_node_props = get_node_props(condition)\n",
    "            condition_node_props['key'] = key\n",
    "            _tx_corroborate_and_ingest(tx, \"Condition\", \"key\", key, condition_node_props, get_rel_props(condition), meta)\n",
    "            tx.run(\"MATCH (p:Product {name: $p_name}), (k:Condition {key: $key}) MERGE (p)-[:HAS_CONDITION]->(k)\", p_name=product_name, key=key)\n",
    "\n",
    "    if data.faqs:\n",
    "        for faq in data.faqs:\n",
    "            if faq is None or faq.question is None: continue\n",
    "            question_value = faq.question.value\n",
    "            faq_node_props = get_node_props(faq)\n",
    "            faq_node_props['question'] = question_value\n",
    "            _tx_corroborate_and_ingest(tx, \"FAQ\", \"question\", question_value, faq_node_props, get_rel_props(faq), meta)\n",
    "            tx.run(\"MATCH (p:Product {name: $p_name}), (f:FAQ {question: $q_value}) MERGE (p)-[:HAS_FAQ]->(f)\", p_name=product_name, q_value=question_value)\n",
    "\n",
    "def _tx_ingest_branch_package(tx: Transaction, package: ExtractionPackage[BranchData]):\n",
    "    \"\"\"Executes the entire branch ingestion in a single transaction.\"\"\"\n",
    "    data = package.data\n",
    "    meta = package.metadata\n",
    "\n",
    "    print(f\"--- â³ STALENESS-CHECK: Deactivating old Branch-facts from {meta.url}...\")\n",
    "    # KORREKTUR: This is NOT an f-string. Use single curly braces.\n",
    "    tx.run(\"MATCH (n:Branch|Employee)-[r:FROM_SOURCE {is_active: true}]->(q:Source {url: $url}) SET r.is_active = false\", url=meta.url)\n",
    "\n",
    "    if not data.branch or not data.branch.name: return\n",
    "    branch_name = data.branch.name.value\n",
    "    print(f\"Processing Branch: {branch_name} from {meta.url}\")\n",
    "    branch_node_props = get_node_props(data.branch)\n",
    "    branch_node_props['name'] = branch_name\n",
    "    _tx_corroborate_and_ingest(tx, \"Branch\", \"name\", branch_name, branch_node_props, get_rel_props(data.branch), meta)\n",
    "\n",
    "    if data.branch.employees:\n",
    "        for employee in data.branch.employees:\n",
    "            if employee is None or employee.name is None: continue\n",
    "            employee_name = employee.name.value\n",
    "            print(f\"-- Processing Employee: {employee_name}\")\n",
    "            employee_node_props = get_node_props(employee)\n",
    "            employee_node_props['name'] = employee_name\n",
    "            _tx_corroborate_and_ingest(tx, \"Employee\", \"name\", employee_name, employee_node_props, get_rel_props(employee), meta)\n",
    "            tx.run(\"MATCH (m:Employee {name: $m_name}), (f:Branch {name: $f_name}) MERGE (m)-[:WORKS_IN]->(f)\", m_name=employee_name, f_name=branch_name)\n",
    "            if employee.role_type:\n",
    "                role_type_name = employee.role_type.value\n",
    "                tx.run(\"MATCH (m:Employee {name: $m_name}) MERGE (st:RoleType {name: $r_name}) MERGE (m)-[:HAS_ROLE_TYPE]->(st)\", m_name=employee_name, r_name=role_type_name)\n",
    "\n",
    "def ingest_product_package(package: ExtractionPackage[KnowledgeGraphData]):\n",
    "    \"\"\"Manager function: Writes a product package in a single transaction.\"\"\"\n",
    "    driver = GraphDatabase.driver(config.NEO4J_URI, auth=(config.NEO4J_USERNAME, config.NEO4J_PASSWORD))\n",
    "    with driver.session() as session:\n",
    "        session.execute_write(_tx_ingest_product_package, package)\n",
    "    print(f\"Ingestion transaction for Product package completed.\")\n",
    "\n",
    "def ingest_branch_package(package: ExtractionPackage[BranchData]):\n",
    "    \"\"\"Manager function: Writes a branch package in a single transaction.\"\"\"\n",
    "    driver = GraphDatabase.driver(config.NEO4J_URI, auth=(config.NEO4J_USERNAME, config.NEO4J_PASSWORD))\n",
    "    with driver.session() as session:\n",
    "        session.execute_write(_tx_ingest_branch_package, package)\n",
    "    print(f\"Ingestion transaction for Branch package completed.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# 4.5 INFERENCE\n",
    "# ==============================================================================\n",
    "def create_inferred_relationships():\n",
    "    \"\"\"Creates inferred relationships ONLY between active nodes.\"\"\"\n",
    "    driver = GraphDatabase.driver(config.NEO4J_URI, auth=(config.NEO4J_USERNAME, config.NEO4J_PASSWORD))\n",
    "    with driver.session() as session:\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\nPHASE 2: CREATE INFERRED RELATIONSHIPS\\n\" + \"=\"*50)\n",
    "\n",
    "        print(\"Deleting all old :ADVISES_ON relationships...\")\n",
    "        session.run(\"MATCH ()-[r:ADVISES_ON]->() DETACH DELETE r\")\n",
    "\n",
    "        cypher_query = \"\"\"\n",
    "        MATCH (m:Employee)-[r_m:FROM_SOURCE]->() WHERE r_m.is_active = true\n",
    "        MATCH (m)-[:HAS_ROLE_TYPE]->(:RoleType {name: 'Advisor'})\n",
    "        MATCH (p:Product)-[r_p:FROM_SOURCE]->() WHERE r_p.is_active = true\n",
    "        MATCH (p)-[:HAS_PRODUCT_TYPE]->(:ProductType {name: 'InterestProduct'})\n",
    "        MERGE (m)-[r:ADVISES_ON]->(p)\n",
    "        RETURN count(r) AS new_relationship_count\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"Creating new relationships between *active* Advisors and *active* InterestProducts...\")\n",
    "        result = session.run(cypher_query)\n",
    "        summary = result.single()\n",
    "        if summary:\n",
    "            print(f\"--> {summary['new_relationship_count']} new :ADVISES_ON relationships created.\")\n",
    "    driver.close()\n",
    "\n",
    "# ==============================================================================\n",
    "# HELPERS\n",
    "# ==============================================================================\n",
    "def clear_database():\n",
    "    \"\"\"Empties the entire Neo4j database.\"\"\"\n",
    "    print(\"Clearing the Neo4j database before starting...\")\n",
    "    driver = GraphDatabase.driver(config.NEO4J_URI, auth=(config.NEO4J_USERNAME, config.NEO4J_PASSWORD))\n",
    "    with driver.session() as s:\n",
    "        s.run(\"MATCH (n) DETACH DELETE n\")\n",
    "    print(\"Database cleared.\")\n",
    "\n",
    "def ingest_fake_data():\n",
    "    \"\"\"\n",
    "    Ingests a single FAKE condition to test the Corroborator logic.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\nðŸ”¬ TEST: Ingesting FAKE Corroborator Data\\n\" + \"=\"*50)\n",
    "\n",
    "    # 1. Define some Fake Data\n",
    "    fake_url = \"https://intern.vblh.de/sparbrief\"\n",
    "    fake_time_str = \"2025-10-02T15:24:42.019052\" # set date in the future or past to test corroborator outcomes\n",
    "    fake_key = \"Volksbank Sparbrief_5000_6\"\n",
    "    fake_product_name = \"Volksbank Sparbrief\"\n",
    "\n",
    "    # 2. Create Pydantic Models\n",
    "    try:\n",
    "        fake_time = datetime.fromisoformat(fake_time_str)\n",
    "        fake_trust = config.get_trust_score(fake_url)\n",
    "\n",
    "        fake_meta = ProvenanceModel(\n",
    "            url=fake_url,\n",
    "            retrieved_at=fake_time,\n",
    "            trust_score=fake_trust\n",
    "        )\n",
    "\n",
    "        fake_condition = ConditionModel(\n",
    "            type=ProvableFact(value=\"Savings Bond\", evidence=\"Fake Entry\"),\n",
    "            min_amount=5000,\n",
    "            max_amount=49999,\n",
    "            term_years=6,\n",
    "            interest_rate=ProvableFact(value=\"2.50%\", evidence=\"Fake Entry: 2.50% (internal)\")\n",
    "        )\n",
    "\n",
    "        # 3. Get Node/Rel Properties\n",
    "        node_props = get_node_props(fake_condition)\n",
    "        node_props['key'] = fake_key\n",
    "        rel_props = get_rel_props(fake_condition)\n",
    "\n",
    "        # 4. Open a DB session and call the Corroborator directly\n",
    "        driver = GraphDatabase.driver(config.NEO4J_URI, auth=(config.NEO4J_USERNAME, config.NEO4J_PASSWORD))\n",
    "        with driver.session() as session:\n",
    "\n",
    "            # Deactivate old facts from this FAKE source first\n",
    "            # KORREKTUR: {{is_active: true}} -> {is_active: true}\n",
    "            session.run(\"\"\"\n",
    "                MATCH (n:Condition)-[r:FROM_SOURCE {is_active: true}]->(q:Source {url: $url})\n",
    "                SET r.is_active = false\n",
    "            \"\"\", url=fake_url)\n",
    "\n",
    "            # Call the Corroborator transaction\n",
    "            session.execute_write(\n",
    "                _tx_corroborate_and_ingest,\n",
    "                \"Condition\",\n",
    "                \"key\",\n",
    "                fake_key,\n",
    "                node_props,\n",
    "                rel_props,\n",
    "                fake_meta\n",
    "            )\n",
    "\n",
    "            # 5. Link the (now active) condition to the product\n",
    "            session.run(\"\"\"\n",
    "                MATCH (p:Product {name: $product_name})\n",
    "                MATCH (k:Condition {key: $key})\n",
    "                MERGE (p)-[:HAS_CONDITION]->(k)\n",
    "            \"\"\", product_name=fake_product_name, key=fake_key)\n",
    "\n",
    "        print(f\"ðŸ”¬ TEST: Fake condition '{fake_key}' for source '{fake_url}' ingested successfully.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ðŸ”¬ TEST ERROR while ingesting fake data: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NHi89hza5rg_"
   },
   "source": [
    "## The Orchestrator\n",
    "\n",
    "This block imports all the logic from our other files and orchestrates the end-to-end pipeline.\n",
    "\n",
    "The flow is:\n",
    "1.  **Phase 0:** Clear the database.\n",
    "2.  **Phase 1 (Real Data):**\n",
    "    * Process Product URLs (Crawl, Extract, Ground, Ingest).\n",
    "    * **Inject Fake Data** to test the Corroborator.\n",
    "    * Process Branch URLs (Crawl, Extract, Ground, Ingest).\n",
    "3.  **Phase 2 (Inference):** Create inferred relationships based on the final *active* state of the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WzmFT7aVJ7K8",
    "outputId": "9506fd7f-df2b-4abd-9a94-58452a8b3ba1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing main.py\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Block 5: main.py\n",
    "# ==============================================================================\n",
    "%%writefile main.py\n",
    "import config\n",
    "from ontology import *\n",
    "from pipeline import (\n",
    "    get_webpage_content,\n",
    "    extract_structured_data,\n",
    "    ground_package,\n",
    "    ingest_product_package,\n",
    "    ingest_branch_package,\n",
    "    create_inferred_relationships,\n",
    "    clear_database,\n",
    "    ingest_fake_data\n",
    ")\n",
    "\n",
    "def run_ingestion():\n",
    "    \"\"\"Executes the entire ingestion process.\"\"\"\n",
    "\n",
    "    # --- PHASE 0: SETUP ---\n",
    "    clear_database()\n",
    "\n",
    "    # --- PHASE 1: REAL DATA INGESTION ---\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\nPHASE 1: STARTING REAL DATA INGESTION\\n\" + \"=\"*50)\n",
    "\n",
    "    # 1a. Process Product URLs\n",
    "    for url in config.TARGET_URLS:\n",
    "        print(\"\\n\" + \"=\"*50 + f\"\\nProcessing PRODUCT URL: {url}\\n\" + \"=\"*50)\n",
    "        webpage_text = get_webpage_content(url)\n",
    "        if webpage_text:\n",
    "            # Step 1: LLM extracts the payload\n",
    "            llm_data = extract_structured_data(text=webpage_text, schema_class=KnowledgeGraphData)\n",
    "\n",
    "            if llm_data:\n",
    "                # Step 2: Create metadata (Provenance & Versioning)\n",
    "                provenance = ProvenanceModel(url=url, trust_score=config.get_trust_score(url))\n",
    "\n",
    "                # Step 3: Bundle the extraction package\n",
    "                package = ExtractionPackage[KnowledgeGraphData](metadata=provenance, data=llm_data)\n",
    "\n",
    "                # --- STEP 3.5: GROUNDING ---\n",
    "                grounded_package = ground_package(package)\n",
    "\n",
    "                # Step 4: Pass the package to the Corroborator/Ingestor\n",
    "                ingest_product_package(grounded_package) # Pass the FILTERED package\n",
    "\n",
    "    # --- PHASE 1.5: FAKE DATA INJECTION (for Corroborator test) ---\n",
    "    ingest_fake_data()\n",
    "\n",
    "    # 1b. Process Branch URLs\n",
    "    for url in config.FILIAL_URLS:\n",
    "        print(\"\\n\" + \"=\"*50 + f\"\\nProcessing BRANCH URL: {url}\\n\" + \"=\"*50)\n",
    "        webpage_text = get_webpage_content(url)\n",
    "        if webpage_text:\n",
    "            # Step 1: LLM extracts the payload\n",
    "            llm_branch_data = extract_structured_data(text=webpage_text, schema_class=BranchData)\n",
    "\n",
    "            if llm_branch_data:\n",
    "                # Step 2: Create metadata\n",
    "                provenance = ProvenanceModel(url=url, trust_score=config.get_trust_score(url))\n",
    "\n",
    "                # Step 3: Bundle the package\n",
    "                package = ExtractionPackage[BranchData](metadata=provenance, data=llm_branch_data)\n",
    "\n",
    "                # --- STEP 3.5: GROUNDING ---\n",
    "                grounded_package = ground_package(package)\n",
    "\n",
    "                # Step 4: Pass the package to the Corroborator/Ingestor\n",
    "                ingest_branch_package(grounded_package) # Pass the FILTERED package\n",
    "\n",
    "    # --- PHASE 2: INFERENCE ---\n",
    "    create_inferred_relationships()\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50 + \"\\nINGESTION PROCESS COMPLETED.\\n\" + \"=\"*50)\n",
    "\n",
    "# This part allows the file to be run as a script\n",
    "if __name__ == \"__main__\":\n",
    "    run_ingestion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iK9rYb6-57WO"
   },
   "source": [
    "## Test Query & Validate\n",
    "\n",
    "This block contains our test queries. It is designed to be run *after* `main.py`.\n",
    "\n",
    "It validates the final state of the graph, proving our logic works:\n",
    "* **Simple Queries (1-5, 9):** These mimic an application (or an LLM-powered search). They *only* query the active facts (e.g., `k.interest_rate` or `r.is_active = true`) and are simple and fast.\n",
    "* **Debug Queries (6-8):** These are for us, the developers. They query the *entire* history (both active and inactive facts) to show that our audit trail and staleness-checks are working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ac_eBsRDKEhE",
    "outputId": "bd2dad7e-c622-433f-c422-5ec42d119140"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing query.py\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Block 6: query.py\n",
    "# ==============================================================================\n",
    "%%writefile query.py\n",
    "from neo4j import GraphDatabase\n",
    "import config\n",
    "\n",
    "def query_graph():\n",
    "    \"\"\"Runs comprehensive test queries against the graph to validate the entire data structure.\"\"\"\n",
    "    driver = GraphDatabase.driver(config.NEO4J_URI, auth=(config.NEO4J_USERNAME, config.NEO4J_PASSWORD))\n",
    "\n",
    "    with driver.session() as session:\n",
    "        print(\"\\n\" + \"=\"*50 + \"\\nRUNNING GRAPH QUERIES\\n\" + \"=\"*50)\n",
    "\n",
    "        # --- Query 1 ---\n",
    "        print(\"\\n--- Query 1: Overview of all *active* products with type and risk class ---\")\n",
    "        query1 = \"\"\"\n",
    "        MATCH (p:Product)-[r_p:FROM_SOURCE]->() WHERE r_p.is_active = true\n",
    "        MATCH (pt:ProductType)<-[:HAS_PRODUCT_TYPE]-(p)-[:HAS_RISK_CLASS]->(s:RiskClass)\n",
    "        RETURN p.name AS Product, pt.name AS Type, s.risk_class AS Risk\n",
    "        ORDER BY Risk, Type, Product\n",
    "        \"\"\"\n",
    "        result1 = session.run(query1)\n",
    "        for record in result1: print(f\"- {record['Product']} (Type: {record['Type']}, Risk: {record['Risk']})\")\n",
    "\n",
    "        # --- Query 2 ---\n",
    "        print(\"\\n--- Query 2: Which *active* employees work in which *active* branch? ---\")\n",
    "        query2 = \"\"\"\n",
    "        MATCH (m:Employee)-[r_m:FROM_SOURCE]->() WHERE r_m.is_active = true\n",
    "        MATCH (f:Branch)-[r_f:FROM_SOURCE]->() WHERE r_f.is_active = true\n",
    "        MATCH (m)-[:WORKS_IN]->(f)\n",
    "        RETURN f.name AS Branch, collect(DISTINCT m.name) AS Employees\n",
    "        ORDER BY Branch\n",
    "        \"\"\"\n",
    "        result2 = session.run(query2)\n",
    "        print(\"(This query now filters out 'stale' employees)\")\n",
    "        for record in result2:\n",
    "            print(f\"Branch '{record['Branch']}':\")\n",
    "            for employee in record['Employees']: print(f\"  - {employee}\")\n",
    "\n",
    "        # --- Query 3 ---\n",
    "        print(\"\\n--- Query 3: Which *active* advisors can advise on *active* interest products? ---\")\n",
    "        query3 = \"\"\"\n",
    "        MATCH (m:Employee)-[r_m:FROM_SOURCE]->() WHERE r_m.is_active = true\n",
    "        MATCH (p:Product)-[r_p:FROM_SOURCE]->() WHERE r_p.is_active = true\n",
    "        MATCH (m)-[:ADVISES_ON]->(p)\n",
    "        RETURN m.name AS Advisor, p.name AS Product\n",
    "        ORDER BY Advisor, Product\n",
    "        \"\"\"\n",
    "        result3 = session.run(query3)\n",
    "        for record in result3: print(f\"- {record['Advisor']} can advise on '{record['Product']}'\")\n",
    "\n",
    "        # --- Query 4 ---\n",
    "        print(\"\\n--- Query 4: Who in Bispingen can *currently* help me with a secure 5-year investment? ---\")\n",
    "        query4 = \"\"\"\n",
    "        MATCH (p:Product)-[r_p:FROM_SOURCE]->() WHERE r_p.is_active = true\n",
    "        MATCH (k:Condition)-[r_k:FROM_SOURCE]->() WHERE r_k.is_active = true\n",
    "        MATCH (p)-[:HAS_CONDITION]->(k)\n",
    "        WHERE k.min_amount <= 60000 AND (k.max_amount IS NULL OR k.max_amount >= 60000) AND k.term_years = 5\n",
    "        WITH p\n",
    "        MATCH (p)-[:HAS_RISK_CLASS]->(s:RiskClass)\n",
    "        WHERE s.risk_class IN ['1', '2']\n",
    "        MATCH (m:Employee)-[r_m:FROM_SOURCE]->() WHERE r_m.is_active = true\n",
    "        MATCH (m)-[:ADVISES_ON]->(p)\n",
    "        MATCH (m)-[:WORKS_IN]->(f:Branch)\n",
    "        WHERE f.name CONTAINS 'Bispingen'\n",
    "        RETURN DISTINCT m.name AS ContactPerson, m.email AS Email\n",
    "        \"\"\"\n",
    "        result4 = session.run(query4)\n",
    "        print(\"Possible *active* contact persons in the Bispingen branch:\")\n",
    "        for record in result4: print(f\"- {record['ContactPerson']} (Email: {record['Email']})\")\n",
    "\n",
    "        # --- Query 5 ---\n",
    "        print(\"\\n--- Query 5: In which *active* branches does Martin Zado work...? ---\")\n",
    "        employee_name = \"Martin Zado\"\n",
    "        query5 = \"\"\"\n",
    "        CYPHER 25\n",
    "        MATCH (m:Employee {name: $name})\n",
    "        LET branches = COLLECT {\n",
    "            MATCH (m)-[:WORKS_IN]->(f:Branch)\n",
    "            MATCH (f)-[r_f:FROM_SOURCE]->() WHERE r_f.is_active = true\n",
    "            RETURN f.name\n",
    "        }\n",
    "        LET advised_products_sk1 = COLLECT {\n",
    "            MATCH (m)-[:ADVISES_ON]->(p:Product)\n",
    "            MATCH (p)-[r_p:FROM_SOURCE]->() WHERE r_p.is_active = true\n",
    "            MATCH (p)-[:HAS_RISK_CLASS]->(s:RiskClass {risk_class: '1'})\n",
    "            RETURN p.name\n",
    "        }\n",
    "        RETURN m.name AS Employee, m.email AS Email, m.phone AS Phone, branches, advised_products_sk1\n",
    "        \"\"\"\n",
    "        try:\n",
    "            result5 = session.run(query5, name=employee_name)\n",
    "            record5 = result5.single()\n",
    "            if not record5: print(f\"Employee '{employee_name}' not found.\")\n",
    "            else:\n",
    "                print(f\"Details for: {record5['Employee']}\")\n",
    "                print(f\"  - Email: {record5['Email']}, Phone: {record5['Phone']}\")\n",
    "                print(f\"  - Works in *active* branches: {record5['branches']}\")\n",
    "                print(f\"  - Advises on *active* products (SK1): {record5['advised_products_sk1']}\")\n",
    "        except Exception as e: print(f\"ERROR during Query 5: {e}\")\n",
    "\n",
    "        # --- Query 6 ---\n",
    "        print(\"\\n--- Query 6 (Debug): Where does the 'Bispingen Branch' fact come from (all versions)? ---\")\n",
    "        query6 = \"\"\"\n",
    "        MATCH (f:Branch)-[r:FROM_SOURCE]->(q:Source)\n",
    "        WHERE f.name CONTAINS 'Bispingen'\n",
    "        RETURN f.name AS Fact, q.url AS Source, r.retrieved_at AS Timestamp, r.is_active AS Active\n",
    "        ORDER BY r.retrieved_at DESC\n",
    "        \"\"\"\n",
    "        result6 = session.run(query6)\n",
    "        for record in result6: print(f\"- Fact: '{record['Fact']}' @ {record['Timestamp']} (Source: {record['Source']}) [Active: {record['Active']}]\")\n",
    "\n",
    "        # --- Query 7 ---\n",
    "        print(\"\\n--- Query 7 (Debug): What facts were *ever* extracted from the savings bond page? ---\")\n",
    "        query7 = \"\"\"\n",
    "        MATCH (n)-[r:FROM_SOURCE]->(q:Source)\n",
    "        WHERE q.url CONTAINS 'sparbrief.html'\n",
    "        RETURN labels(n) AS Type, COALESCE(n.name, n.key, n.question) AS NameOrKey, r.retrieved_at AS Timestamp, r.is_active AS Active\n",
    "        ORDER BY Timestamp DESC, Type, NameOrKey\n",
    "        \"\"\"\n",
    "        result7 = session.run(query7)\n",
    "        print(f\"Facts from savings bond page (newest first):\")\n",
    "        for record in result7: print(f\"- [{record['Type'][0]}] {record['NameOrKey']} (Retrieved: {record['Timestamp']}) [Active: {record['Active']}]\")\n",
    "\n",
    "        # --- Query 8 ---\n",
    "        print(\"\\n--- Query 8 (Debug): What is the *evidence* for a branch named Bispingen? ---\")\n",
    "        query8 = \"\"\"\n",
    "        MATCH (f:Branch)-[r:FROM_SOURCE]->(q:Source)\n",
    "        WHERE f.name CONTAINS 'Bispingen' AND r.name_evidence IS NOT NULL\n",
    "        RETURN f.name AS FactValue, r.name_evidence AS FactEvidence, q.url AS Source, r.retrieved_at AS Timestamp, r.is_active AS Active\n",
    "        ORDER BY r.retrieved_at DESC\n",
    "        LIMIT 1\n",
    "        \"\"\"\n",
    "        result8 = session.run(query8)\n",
    "        record8 = result8.single()\n",
    "        if record8: print(f\"- Fact (found): '{record8['FactValue']}' (Newest from {record8['Timestamp']}) [Active: {record8['Active']}]\\n  Evidence: '{record8['FactEvidence']}'\")\n",
    "        else: print(\"No evidence found for a branch named 'Bispingen'.\")\n",
    "\n",
    "        # --- Query 9 ---\n",
    "        print(\"\\n--- Query 9: 'How much interest for 30,000â‚¬ for 5 years?' ---\")\n",
    "        investment_amount = 30000\n",
    "        investment_years = 5\n",
    "        query9 = \"\"\"\n",
    "        MATCH (p:Product)-[:HAS_CONDITION]->(k:Condition)\n",
    "        MATCH (k)-[r_k:FROM_SOURCE]->()\n",
    "        WHERE r_k.is_active = true\n",
    "\n",
    "        AND k.min_amount <= $amount\n",
    "        AND (k.max_amount IS NULL OR k.max_amount >= $amount)\n",
    "        AND k.term_years = $years\n",
    "\n",
    "        RETURN p.name AS Product, k.interest_rate AS InterestRate, k.type AS ConditionType\n",
    "        \"\"\"\n",
    "        result9 = session.run(query9, amount=investment_amount, years=investment_years)\n",
    "        print(f\"Results for an *active* investment of {investment_amount}â‚¬ over {investment_years} years:\")\n",
    "        records9 = list(result9)\n",
    "        if not records9: print(\"  -> No matching *active* conditions found.\")\n",
    "        else:\n",
    "            for record in records9: print(f\"  - Product: '{record['Product']}', Interest Rate: {record['InterestRate']} (Type: {record['ConditionType']})\")\n",
    "\n",
    "    driver.close()\n",
    "\n",
    "# allow the file to be run as a script\n",
    "if __name__ == \"__main__\":\n",
    "    query_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y6QGXFjUxOVY"
   },
   "source": [
    "# Test LLM as a judge\n",
    "\n",
    "Recent research have show that LLM as a jusdge is a valid strategy for evaluation generative output of out model.\n",
    "\n",
    "We use it as a way to evaluate the system out put of our models.\n",
    "\n",
    "The model are ask to evaluate on:\n",
    "* Precision\n",
    "* Faithfulness\n",
    "* Comprehensiveness\n",
    "* Relevant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-26T08:23:44.425981Z",
     "iopub.status.busy": "2025-12-26T08:23:44.425823Z",
     "iopub.status.idle": "2025-12-26T08:24:47.438123Z",
     "shell.execute_reply": "2025-12-26T08:24:47.437169Z",
     "shell.execute_reply.started": "2025-12-26T08:23:44.425970Z"
    },
    "id": "z3EEbEx2xTVo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Whole-answer evaluation:\n",
      "  precision_score faithfulness_score comprehensiveness_score relevance_score  \\\n",
      "0               3                  2                       3               4   \n",
      "\n",
      "  overall_score                                          reasoning  \n",
      "0             3  {'precision': 'The triples are generally clear...  \n",
      "\n",
      "Per-triple evaluations (appended):\n",
      "  precision_score faithfulness_score comprehensiveness_score relevance_score  \\\n",
      "1               5                  5                       5               5   \n",
      "2               5                  5                       4               5   \n",
      "3               5                  5                       4               5   \n",
      "4               5                  5                       4               5   \n",
      "5               5                  5                       5               5   \n",
      "6               5                  5                       4               5   \n",
      "7               4                  5                       3               5   \n",
      "8               5                  5                       4               5   \n",
      "9               5                  5                       5               5   \n",
      "\n",
      "  overall_score                                          reasoning  \n",
      "1             5  {'precision': 'The triple is concise, uses cor...  \n",
      "2             5  {'precision': 'The triple is clear, specific, ...  \n",
      "3             5  {'precision': 'The triple is concise, correctl...  \n",
      "4             5  {'precision': 'The triple is concise, uses the...  \n",
      "5             5  {'precision': 'The triple is clear, specific, ...  \n",
      "6             5  {'precision': 'The triple is specific and accu...  \n",
      "7             4  {'precision': 'The triple is clear and specifi...  \n",
      "8             5  {'precision': 'The triple accurately captures ...  \n",
      "9             5  {'precision': 'The triple is clear, specific, ...  \n"
     ]
    }
   ],
   "source": [
    "#%%writefile llm_judge.py\n",
    "\n",
    "#%%writefile llm_judge.py\n",
    "import html\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import requests\n",
    "from typing import Optional, Dict, Any, List\n",
    "\n",
    "\n",
    "# Prompt used as SYSTEM input for our LLM judge\n",
    "JUDGE_PROMPT = \"\"\"\n",
    "You are an expert financial evaluator and LLM judge. Your role is to assess the quality of a system-generated answer to a user question based on four dimensions:\n",
    "\n",
    "1. **Precision** â€“ Is the answer clear, specific, and accurate?\n",
    "2. **Faithfulness** â€“ Does the answer remain factually correct and grounded in the source text?\n",
    "3. **Comprehensiveness** â€“ Does the answer fully capture the core information and context?\n",
    "4. **Relevance** â€“ Is the answer aligned with the main topic and intent of the user question?\n",
    "\n",
    "### Instructions:\n",
    "- Rate each dimension on a scale of **1 to 5** (1 = very poor, 5 = excellent).\n",
    "- Provide a **final overall score** (average or weighted if needed).\n",
    "- Explain your reasoning for each dimension clearly and concisely.\n",
    "- Output your evaluation in **valid JSON format** as shown below.\n",
    "\n",
    "### Output Format:\n",
    "<ANSWER>\n",
    "{\n",
    "  \"precision_score\": <integer>,\n",
    "  \"faithfulness_score\": <integer>,\n",
    "  \"comprehensiveness_score\": <integer>,\n",
    "  \"relevance_score\": <integer>,\n",
    "  \"overall_score\": <integer>,\n",
    "  \"reasoning\": {\n",
    "    \"precision\": \"<your explanation>\",\n",
    "    \"faithfulness\": \"<your explanation>\",\n",
    "    \"comprehensiveness\": \"<your explanation>\",\n",
    "    \"relevance\": \"<your explanation>\",\n",
    "    \"overall\": \"<summary of judgment>\"\n",
    "  }\n",
    "}\n",
    "</ANSWER>\n",
    "\n",
    "### Additional Guidelines:\n",
    "- Be **objective and consistent** in scoring.\n",
    "- If information is missing or ambiguous, deduct points and explain why.\n",
    "- Do not include any extra text outside the JSON block.\n",
    "<ANSWER>{}</ANSWER>\n",
    "\"\"\".strip()\n",
    "\n",
    "TEST_ORIGIN_TEXT = \"\"\"\n",
    "Apple There's little question that Apple (NASDAQ: AAPL) has become one of the most successful companies in history. \n",
    "It was clear that CEO Jensen Huang had a knack for skating to where the puck was going -- recognizing technology trends on the fly and adapting Nvidia's processors and the accompanying software to meet that need. \n",
    "The company, which began as a local online auction site, has evolved into the largest e-commerce and payments ecosystem in Latin America, serving 18 countries in the region.\n",
    "\"\"\".strip()\n",
    "\n",
    "# Generated sample from Copilot based on the origin text for evaluating the output\n",
    "TEST_TRIPLET = {\n",
    "  \"triples\": [\n",
    "    {\n",
    "      \"subject\": \"Apple\",\n",
    "      \"predicate\": \"has become\",\n",
    "      \"object\": \"one of the most successful companies in history\",\n",
    "      \"evidence\": \"Apple There's little question that Apple (NASDAQ: AAPL) has become one of the most successful companies in history.\",\n",
    "      \"subject_type\": \"Organization\",\n",
    "      \"object_type\": \"Descriptor\",\n",
    "      \"confidence\": 0.95\n",
    "    },\n",
    "    {\n",
    "      \"subject\": \"Apple\",\n",
    "      \"predicate\": \"ticker symbol\",\n",
    "      \"object\": \"NASDAQ: AAPL\",\n",
    "      \"evidence\": \"Apple (NASDAQ: AAPL)\",\n",
    "      \"subject_type\": \"Organization\",\n",
    "      \"object_type\": \"TickerSymbol\",\n",
    "      \"confidence\": 0.99\n",
    "    },\n",
    "    {\n",
    "      \"subject\": \"Jensen Huang\",\n",
    "      \"predicate\": \"role\",\n",
    "      \"object\": \"CEO\",\n",
    "      \"evidence\": \"It was clear that CEO Jensen Huang had a knack...\",\n",
    "      \"subject_type\": \"Person\",\n",
    "      \"object_type\": \"Role\",\n",
    "      \"confidence\": 0.9\n",
    "    },\n",
    "    {\n",
    "      \"subject\": \"Jensen Huang\",\n",
    "      \"predicate\": \"recognized\",\n",
    "      \"object\": \"technology trends on the fly\",\n",
    "      \"evidence\": \"recognizing technology trends on the fly\",\n",
    "      \"subject_type\": \"Person\",\n",
    "      \"object_type\": \"Concept\",\n",
    "      \"confidence\": 0.85\n",
    "    },\n",
    "    {\n",
    "      \"subject\": \"Jensen Huang\",\n",
    "      \"predicate\": \"adapted\",\n",
    "      \"object\": \"Nvidia's processors and software to meet technology needs\",\n",
    "      \"evidence\": \"adapting Nvidia's processors and the accompanying software to meet that need.\",\n",
    "      \"subject_type\": \"Person\",\n",
    "      \"object_type\": \"Product/Software\",\n",
    "      \"confidence\": 0.88\n",
    "    },\n",
    "    {\n",
    "      \"subject\": \"Nvidia\",\n",
    "      \"predicate\": \"has products\",\n",
    "      \"object\": \"processors and accompanying software\",\n",
    "      \"evidence\": \"adapting Nvidia's processors and the accompanying software\",\n",
    "      \"subject_type\": \"Organization\",\n",
    "      \"object_type\": \"Product/Software\",\n",
    "      \"confidence\": 0.8\n",
    "    },\n",
    "    {\n",
    "      \"subject\": \"Unnamed company\",\n",
    "      \"predicate\": \"began as\",\n",
    "      \"object\": \"local online auction site\",\n",
    "      \"evidence\": \"The company, which began as a local online auction site,\",\n",
    "      \"subject_type\": \"Organization\",\n",
    "      \"object_type\": \"Activity\",\n",
    "      \"confidence\": 0.75\n",
    "    },\n",
    "    {\n",
    "      \"subject\": \"Unnamed company\",\n",
    "      \"predicate\": \"evolved into\",\n",
    "      \"object\": \"largest e-commerce and payments ecosystem in Latin America\",\n",
    "      \"evidence\": \"has evolved into the largest e-commerce and payments ecosystem in Latin America,\",\n",
    "      \"subject_type\": \"Organization\",\n",
    "      \"object_type\": \"OrganizationDescriptor\",\n",
    "      \"confidence\": 0.82\n",
    "    },\n",
    "    {\n",
    "      \"subject\": \"Largest e-commerce and payments ecosystem in Latin America\",\n",
    "      \"predicate\": \"serves\",\n",
    "      \"object\": \"18 countries in the region\",\n",
    "      \"evidence\": \"serving 18 countries in the region.\",\n",
    "      \"subject_type\": \"OrganizationDescriptor\",\n",
    "      \"object_type\": \"GeographicScope\",\n",
    "      \"confidence\": 0.8\n",
    "    }\n",
    "  ],\n",
    "  \"notes\": [\n",
    "    \"The text refers to 'CEO Jensen Huang' in the context of Nvidia, implying the role at Nvidia.\",\n",
    "    \"The final paragraph describes an unnamed company; if the source is MercadoLibre (commonly matching this description), its name is not explicitly stated in the provided text, so we retain 'Unnamed company' to avoid assumptions.\"\n",
    "  ]\n",
    "}\n",
    "\n",
    "\n",
    "# -------------------------- LM Studio Client -------------------------- #\n",
    "class LMStudioLLM:\n",
    "    \"\"\"\n",
    "    Minimal, testable client for LM Studio's REST API with a callable interface.\n",
    "\n",
    "    Usage:\n",
    "        llm = LMStudioLLM(\n",
    "            model=\"openai/gpt-oss-20b\",\n",
    "            base_url=\"http://localhost:1234\",\n",
    "            timeout=30,\n",
    "            temperature=0.2,\n",
    "            max_tokens=512,\n",
    "        )\n",
    "        output_text = llm(prompt_text)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: str,\n",
    "        base_url: str = \"http://localhost:1234\",\n",
    "        timeout: float = 30.0,\n",
    "        temperature: float = 0.2,\n",
    "        max_tokens: int = 512,\n",
    "        session: Optional[requests.Session] = None,\n",
    "        system_message: Optional[str] = None,\n",
    "    ):\n",
    "        self.model = model\n",
    "        self.base_url = base_url.rstrip(\"/\")\n",
    "        self.timeout = timeout\n",
    "        self.temperature = temperature\n",
    "        self.max_tokens = max_tokens\n",
    "        self.session = session or requests.Session()\n",
    "        self.system_message = system_message  # If None, you can pass system content per call\n",
    "\n",
    "        self._chat_url = f\"{self.base_url}/v1/chat/completions\"\n",
    "\n",
    "    def __call__(self, user_prompt: str, system_prompt: Optional[str] = None) -> str:\n",
    "        \"\"\"\n",
    "        Call the LM Studio chat endpoint and return the assistant content as string.\n",
    "        \"\"\"\n",
    "        headers = {\"Content-Type\": \"application/json\"}\n",
    "        messages = []\n",
    "\n",
    "        # Prefer explicitly provided system prompt; fall back to self.system_message\n",
    "        sys_content = system_prompt if system_prompt is not None else self.system_message\n",
    "        if sys_content:\n",
    "            messages.append({\"role\": \"system\", \"content\": sys_content})\n",
    "\n",
    "        messages.append({\"role\": \"user\", \"content\": user_prompt})\n",
    "\n",
    "        payload = {\n",
    "            \"model\": self.model,\n",
    "            \"messages\": messages,\n",
    "            \"temperature\": self.temperature,\n",
    "            \"max_tokens\": self.max_tokens,\n",
    "        }\n",
    "\n",
    "        resp = self.session.post(self._chat_url, headers=headers, data=json.dumps(payload), timeout=self.timeout)\n",
    "        if resp.status_code >= 400:\n",
    "            raise RuntimeError(f\"LM Studio HTTP {resp.status_code}: {resp.text}\")\n",
    "\n",
    "        raw = resp.json()\n",
    "        try:\n",
    "            return raw[\"choices\"][0][\"message\"][\"content\"]\n",
    "        except (KeyError, IndexError, TypeError):\n",
    "            return \"\"\n",
    "\n",
    "\n",
    "# -------------------------- Judge Module -------------------------- #\n",
    "class LLM_Judge:\n",
    "    def __init__(self, llm_callable: LMStudioLLM):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            llm_callable: A callable that accepts (prompt: str, system_prompt?: str) and returns a string.\n",
    "        \"\"\"\n",
    "        self.llm = llm_callable\n",
    "        self.prompt = JUDGE_PROMPT\n",
    "        self.columns = [\n",
    "            \"precision_score\",\n",
    "            \"faithfulness_score\",\n",
    "            \"comprehensiveness_score\",\n",
    "            \"relevance_score\",\n",
    "            \"overall_score\",\n",
    "            \"reasoning\",\n",
    "        ]\n",
    "        self.result = pd.DataFrame(columns=self.columns)\n",
    "\n",
    "\n",
    "    def _extract_raw_output(self, raw_output: str) -> Optional[str]:\n",
    "        \"\"\"\n",
    "        Extract JSON block between <ANSWER> ... </ANSWER>.\n",
    "        - Unescapes HTML entities first.\n",
    "        - Falls back to extracting the first JSON object if tags are missing.\n",
    "        \"\"\"\n",
    "        if not raw_output:\n",
    "            return None\n",
    "    \n",
    "        text = html.unescape(raw_output)\n",
    "    \n",
    "        # Primary: look for tags\n",
    "        start = text.find(\"<ANSWER>\")\n",
    "        end = text.find(\"</ANSWER>\")\n",
    "        if start != -1 and end != -1 and end > start:\n",
    "            return text[start + len(\"<ANSWER>\"): end].strip()\n",
    "    \n",
    "        # Secondary: try to extract first JSON object via brace matching\n",
    "        # This handles cases where the model omits the tags but returns pure JSON.\n",
    "        first_brace = text.find(\"{\")\n",
    "        if first_brace != -1:\n",
    "            depth = 0\n",
    "            for i in range(first_brace, len(text)):\n",
    "                if text[i] == \"{\":\n",
    "                    depth += 1\n",
    "                elif text[i] == \"}\":\n",
    "                    depth -= 1\n",
    "                    if depth == 0:\n",
    "                        candidate = text[first_brace:i+1]\n",
    "                        candidate = candidate.strip()\n",
    "                        # Sanity check for JSON-like content\n",
    "                        if candidate.startswith(\"{\") and candidate.endswith(\"}\"):\n",
    "                            return candidate\n",
    "    \n",
    "        # Tertiary: regex-based attempt (less reliable but sometimes useful)\n",
    "        m = re.search(r\"\\{(?:[^{}]|(?R))*\\}\", text)  # nested braces not fully supported in Python regex\n",
    "        if m:\n",
    "            return m.group(0).strip()\n",
    "    \n",
    "        return None\n",
    "\n",
    "\n",
    "    def _build_eval_prompt(self, origin_text: str, system_answer_json: Dict[str, Any]) -> str:\n",
    "        \"\"\"\n",
    "        Build the user message that provides context for the judge.\n",
    "        \"\"\"\n",
    "        return (\n",
    "            \"User Question: Extract subjectâ€“predicateâ€“object triples from the source text.\\n\\n\"\n",
    "            \"Source Text:\\n\"\n",
    "            f\"{origin_text}\\n\\n\"\n",
    "            \"System-Generated Answer (JSON):\\n\"\n",
    "            f\"{json.dumps(system_answer_json, ensure_ascii=False, indent=2)}\\n\\n\"\n",
    "            \"Please evaluate the System-Generated Answer strictly based on the Source Text.\\n\"\n",
    "            \"Output ONLY the JSON inside <ANSWER>...</ANSWER> tags, per the system instructions.\"\n",
    "        )\n",
    "\n",
    "    def evaluate(self, origin_text: str, relevant_triplet: Dict[str, Any]) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Evaluate the entire generated triple set once and store the JSON result.\n",
    "        Returns the current results DataFrame.\n",
    "        \"\"\"\n",
    "        user_prompt = self._build_eval_prompt(origin_text, relevant_triplet)\n",
    "        raw_output = self.llm(user_prompt, system_prompt=self.prompt)\n",
    "        answer_block = self._extract_raw_output(raw_output)\n",
    "\n",
    "        if answer_block is None:\n",
    "            raise ValueError(\"Could not find <ANSWER>...</ANSWER> block in model output.\")\n",
    "\n",
    "        try:\n",
    "            evaluation = json.loads(answer_block)\n",
    "        except json.JSONDecodeError as e:\n",
    "            raise ValueError(f\"Error parsing JSON from model output: {e}\\nRaw: {answer_block}\")\n",
    "\n",
    "        # Normalize reasoning into a single string for DataFrame or keep dict\n",
    "        if \"reasoning\" in evaluation and isinstance(evaluation[\"reasoning\"], dict):\n",
    "            # Keep as dict, store in the 'reasoning' column\n",
    "            row = {\n",
    "                \"precision_score\": evaluation.get(\"precision_score\"),\n",
    "                \"faithfulness_score\": evaluation.get(\"faithfulness_score\"),\n",
    "                \"comprehensiveness_score\": evaluation.get(\"comprehensiveness_score\"),\n",
    "                \"relevance_score\": evaluation.get(\"relevance_score\"),\n",
    "                \"overall_score\": evaluation.get(\"overall_score\"),\n",
    "                \"reasoning\": evaluation[\"reasoning\"],\n",
    "            }\n",
    "        else:\n",
    "            # Fallback: place the entire evaluation in reasoning\n",
    "            row = {\n",
    "                \"precision_score\": evaluation.get(\"precision_score\"),\n",
    "                \"faithfulness_score\": evaluation.get(\"faithfulness_score\"),\n",
    "                \"comprehensiveness_score\": evaluation.get(\"comprehensiveness_score\"),\n",
    "                \"relevance_score\": evaluation.get(\"relevance_score\"),\n",
    "                \"overall_score\": evaluation.get(\"overall_score\"),\n",
    "                \"reasoning\": evaluation.get(\"reasoning\"),\n",
    "            }\n",
    "\n",
    "        self.result = pd.concat([self.result, pd.DataFrame([row])], ignore_index=True)\n",
    "        return self.result\n",
    "\n",
    "    def evaluate_per_triple(self, origin_text: str, relevant_triplet: Dict[str, Any]) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Optional: Evaluate each triple individually and append all results.\n",
    "\n",
    "        Returns:\n",
    "            DataFrame with one row per triple evaluation.\n",
    "        \"\"\"\n",
    "        triples: List[Dict[str, Any]] = relevant_triplet.get(\"triples\", [])\n",
    "        if not triples:\n",
    "            raise ValueError(\"No 'triples' found in relevant_triplet.\")\n",
    "\n",
    "        rows = []\n",
    "        for i, triple in enumerate(triples, start=1):\n",
    "            per_triple_answer = {\"triple\": triple}\n",
    "            user_prompt = (\n",
    "                \"User Question: Evaluate the correctness of a single extracted triple against the source text.\\n\\n\"\n",
    "                \"Source Text:\\n\"\n",
    "                f\"{origin_text}\\n\\n\"\n",
    "                \"Triple Under Review (JSON):\\n\"\n",
    "                f\"{json.dumps(per_triple_answer, ensure_ascii=False, indent=2)}\\n\\n\"\n",
    "                \"Please evaluate strictly based on the Source Text.\\n\"\n",
    "                \"Output ONLY the JSON inside <ANSWER>...</ANSWER> tags, per the system instructions.\"\n",
    "            )\n",
    "\n",
    "            raw_output = self.llm(user_prompt, system_prompt=self.prompt)\n",
    "            answer_block = self._extract_raw_output(raw_output)\n",
    "            if answer_block is None:\n",
    "                # Skip but record a placeholder row\n",
    "                rows.append({\n",
    "                    \"precision_score\": None,\n",
    "                    \"faithfulness_score\": None,\n",
    "                    \"comprehensiveness_score\": None,\n",
    "                    \"relevance_score\": None,\n",
    "                    \"overall_score\": None,\n",
    "                    \"reasoning\": {\"overall\": f\"Missing <ANSWER> tags for triple #{i}.\"}\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                evaluation = json.loads(answer_block)\n",
    "                rows.append({\n",
    "                    \"precision_score\": evaluation.get(\"precision_score\"),\n",
    "                    \"faithfulness_score\": evaluation.get(\"faithfulness_score\"),\n",
    "                    \"comprehensiveness_score\": evaluation.get(\"comprehensiveness_score\"),\n",
    "                    \"relevance_score\": evaluation.get(\"relevance_score\"),\n",
    "                    \"overall_score\": evaluation.get(\"overall_score\"),\n",
    "                    \"reasoning\": evaluation.get(\"reasoning\"),\n",
    "                })\n",
    "            except json.JSONDecodeError:\n",
    "                rows.append({\n",
    "                    \"precision_score\": None,\n",
    "                    \"faithfulness_score\": None,\n",
    "                    \"comprehensiveness_score\": None,\n",
    "                    \"relevance_score\": None,\n",
    "                    \"overall_score\": None,\n",
    "                    \"reasoning\": {\"overall\": f\"JSON parse error for triple #{i}.\"}\n",
    "                })\n",
    "\n",
    "        df = pd.DataFrame(rows)\n",
    "        self.result = pd.concat([self.result, df], ignore_index=True)\n",
    "        return self.result\n",
    "\n",
    "    def return_results(self) -> pd.DataFrame:\n",
    "        return self.result\n",
    "\n",
    "\n",
    "# -------------------------- Example Usage -------------------------- #\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) Instantiate LM Studio client (adjust model name to what you've loaded in LM Studio)\n",
    "    llm = LMStudioLLM(\n",
    "        model=\"openai/gpt-oss-20b\",\n",
    "        base_url=\"http://localhost:1234\", # Replace with the host instance of LMStudio, this is the default\n",
    "        temperature=0.1,\n",
    "        max_tokens=512,\n",
    "    )\n",
    "\n",
    "    # 2) Create Judge\n",
    "    judge = LLM_Judge(llm)\n",
    "\n",
    "    # 3a) Evaluate the whole answer (triples JSON)\n",
    "    try:\n",
    "        results_df = judge.evaluate(TEST_ORIGIN_TEXT, TEST_TRIPLET)\n",
    "        print(\"Whole-answer evaluation:\")\n",
    "        print(results_df.tail(1))\n",
    "    except Exception as e:\n",
    "        print(\"Evaluation error:\", e)\n",
    "\n",
    "    # 3b) (Optional) Evaluate per triple\n",
    "    try:\n",
    "        per_triple_df = judge.evaluate_per_triple(TEST_ORIGIN_TEXT, TEST_TRIPLET)\n",
    "        print(\"\\nPer-triple evaluations (appended):\")\n",
    "        print(per_triple_df.tail(len(TEST_TRIPLET[\"triples\"])))\n",
    "    except Exception as e:\n",
    "        print(\"Per-triple evaluation error:\", e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KmYnOPZB6Dk9"
   },
   "source": [
    "## Run Pipeline & Query\n",
    "\n",
    "This final block executes our application.\n",
    "1.  `main.run_ingestion()`: Runs the complete ETL pipeline (Clear DB, Crawl, Extract, Ground, Ingest, Infer).\n",
    "2.  `query.query_graph()`: Runs all test queries to validate the final state of the Knowledge Graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "id": "cjvk6vhEKN7X",
    "outputId": "150ea126-9737-46ee-e27c-3a0cad0cc843"
   },
   "outputs": [
    {
     "ename": "SecretNotFoundError",
     "evalue": "Secret NEO4J_URI does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSecretNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1876574198.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Block 7: Run the ingstion and query tests\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# ==============================================================================\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/main.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0montology\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m from pipeline import (\n\u001b[1;32m      4\u001b[0m     \u001b[0mget_webpage_content\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mextract_structured_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/content/config.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# --- API Keys ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mNEO4J_URI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NEO4J_URI'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mNEO4J_USERNAME\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NEO4J_USERNAME'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mNEO4J_PASSWORD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muserdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NEO4J_PASSWORD'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/userdata.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'exists'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mSecretNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'access'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mNotebookAccessError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSecretNotFoundError\u001b[0m: Secret NEO4J_URI does not exist."
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "# Block 7: Run the ingstion and query tests\n",
    "# ==============================================================================\n",
    "import main\n",
    "import query\n",
    "\n",
    "main.run_ingestion()\n",
    "\n",
    "query.query_graph()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
